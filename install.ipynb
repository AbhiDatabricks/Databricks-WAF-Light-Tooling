{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16850c79-c080-4a33-95d0-b7acba5fa04d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# If notebook is in the repo root, and dashboard is in dashboards/\n",
    "import os, json, base64, requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Get user and context info\n",
    "user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "ctx = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "api_url = ctx.apiUrl().get()\n",
    "token = ctx.apiToken().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4dd3c35-2614-4d90-bd16-4f7d0cd43a35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get current notebook path and compute dashboards folder\n",
    "notebook_path = ctx.notebookPath().get()\n",
    "base_path = \"/\".join(notebook_path.split(\"/\")[:-1])\n",
    "dashboard_folder = os.path.join(os.getcwd(), \"dashboards\")\n",
    "workspace_base_path = f\"{base_path}/dashboards\"\n",
    "\n",
    "# Generate timestamp for unique dashboard naming\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "print(f\"üïê Installation timestamp: {timestamp}\")\n",
    "\n",
    "print(f\"üìÇ Dashboard folder path: {dashboard_folder}\")\n",
    "print(f\"üìÅ Found {len(os.listdir(dashboard_folder))} file(s) in {dashboard_folder}\")\n",
    "\n",
    "# Log install info - Comment out the next line to disable telemetry\n",
    "ENABLE_TELEMETRY = True  # Set to False or comment out to disable usage analytics\n",
    "\n",
    "if ENABLE_TELEMETRY:\n",
    "    try:\n",
    "        # Extract workspace ID from the API URL or notebook path\n",
    "        workspace_id = api_url.split(\"/\")[2].split(\".\")[0]  # Gets workspace from URL like https://dbc-abc123.cloud.databricks.com\n",
    "        \n",
    "        # Mask the email - only mask first 5 characters\n",
    "        if '@' in user:\n",
    "            username, domain = user.split('@')\n",
    "            if len(username) > 5:\n",
    "                masked_user = '*' * 5 + username[5:] + '@' + domain\n",
    "            else:\n",
    "                masked_user = '*' * len(username) + '@' + domain\n",
    "        else:\n",
    "            masked_user = user  # If no @ symbol, use as is\n",
    "        \n",
    "        log_response = requests.post(\n",
    "            'http://87.121.93.91:8080/api/log',\n",
    "        headers={\n",
    "            'x-api-key': 'chaplin',\n",
    "            'Content-Type': 'application/json'\n",
    "        },\n",
    "            json={\n",
    "                'workspace_id': workspace_id,\n",
    "                'user': masked_user  # Send masked email instead of full email\n",
    "            },\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if log_response.status_code == 201:\n",
    "            print(f\"üìä Activity logged successfully for workspace: {workspace_id}, user: {masked_user}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Failed to log activity: {log_response.status_code}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Logging error: {str(e)}\")\n",
    "\n",
    "for fname in os.listdir(dashboard_folder):\n",
    "    if fname.endswith(\".lvdash.json\"):\n",
    "        base_dashboard_name = fname.replace(\".lvdash.json\", \"\")\n",
    "        # Add timestamp to make dashboard name unique\n",
    "        dashboard_name = f\"{base_dashboard_name}_{timestamp}\"\n",
    "        \n",
    "        print(f\"\\nüìä Processing: {base_dashboard_name}\")\n",
    "        print(f\"   ‚û°Ô∏è  Will create as: {dashboard_name}\")\n",
    "        \n",
    "        with open(os.path.join(dashboard_folder, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            dashboard_def = json.load(f)\n",
    "\n",
    "        # First, try to create the dashboard\n",
    "        response = requests.post(\n",
    "            url=f\"{api_url}/api/2.0/lakeview/dashboards\",\n",
    "            headers={\n",
    "                \"Authorization\": f\"Bearer {token}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            },\n",
    "            json={\n",
    "                \"display_name\": dashboard_name,\n",
    "                \"parent_path\": workspace_base_path,\n",
    "                \"serialized_dashboard\": json.dumps(dashboard_def),\n",
    "                \"warehouse_id\": None  # Will use default warehouse\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200 or response.status_code == 201:\n",
    "            result = response.json()\n",
    "            dashboard_id = result.get(\"dashboard_id\", \"\")\n",
    "            dashboard_path = result.get(\"path\", \"\")\n",
    "            print(f\"‚úÖ Created Lakeview Dashboard: {dashboard_name}\")\n",
    "            print(f\"   üìä Dashboard ID: {dashboard_id}\")\n",
    "            print(f\"   üîó Path: {dashboard_path}\")\n",
    "            print(f\"   üåê URL: {api_url}/sql/dashboardsv3/{dashboard_id}\")\n",
    "        elif response.status_code == 400:\n",
    "            # Check if it's a RESOURCE_ALREADY_EXISTS error\n",
    "            try:\n",
    "                error_json = response.json()\n",
    "                if error_json.get(\"error_code\") == \"RESOURCE_ALREADY_EXISTS\":\n",
    "                    print(f\"‚ö†Ô∏è  Dashboard '{dashboard_name}' already exists. Finding and updating...\")\n",
    "                    \n",
    "                    # List all dashboards to find the existing one\n",
    "                    list_response = requests.get(\n",
    "                        url=f\"{api_url}/api/2.0/lakeview/dashboards\",\n",
    "                        headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                    )\n",
    "                    \n",
    "                    if list_response.status_code == 200:\n",
    "                        dashboards = list_response.json().get(\"dashboards\", [])\n",
    "                        existing_dashboard = None\n",
    "                        \n",
    "                        # Find the dashboard by name\n",
    "                        for dash in dashboards:\n",
    "                            if dash.get(\"display_name\") == dashboard_name or dash.get(\"display_name\") == f\"{dashboard_name}.lvdash.json\":\n",
    "                                existing_dashboard = dash\n",
    "                                break\n",
    "                        \n",
    "                        if existing_dashboard:\n",
    "                            dashboard_id = existing_dashboard[\"dashboard_id\"]\n",
    "                            \n",
    "                            # Update the existing dashboard using PATCH\n",
    "                            update_response = requests.patch(\n",
    "                                url=f\"{api_url}/api/2.0/lakeview/dashboards/{dashboard_id}\",\n",
    "                                headers={\n",
    "                                    \"Authorization\": f\"Bearer {token}\",\n",
    "                                    \"Content-Type\": \"application/json\"\n",
    "                                },\n",
    "                                json={\n",
    "                                    \"serialized_dashboard\": json.dumps(dashboard_def)\n",
    "                                }\n",
    "                            )\n",
    "                            \n",
    "                            if update_response.status_code == 200:\n",
    "                                result = update_response.json()\n",
    "                                print(f\"‚úÖ Updated Lakeview Dashboard: {dashboard_name}\")\n",
    "                                print(f\"   üìä Dashboard ID: {dashboard_id}\")\n",
    "                                print(f\"   üîó Path: {existing_dashboard.get('path', '')}\")\n",
    "                                print(f\"   üåê URL: {api_url}/sql/dashboardsv3/{dashboard_id}\")\n",
    "                            else:\n",
    "                                print(f\"‚ùå Failed to update dashboard: {dashboard_name} ‚Äî Status: {update_response.status_code}\")\n",
    "                                print(f\"Error Response: {update_response.text}\")\n",
    "                        else:\n",
    "                            print(f\"‚ùå Could not find existing dashboard: {dashboard_name}\")\n",
    "                    else:\n",
    "                        print(f\"‚ùå Failed to list dashboards ‚Äî Status: {list_response.status_code}\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Failed to import: {dashboard_name} ‚Äî Status: {response.status_code}\")\n",
    "                    print(f\"Error Response: {response.text}\")\n",
    "                    print(f\"Error Details: {json.dumps(error_json, indent=2)}\")\n",
    "            except:\n",
    "                print(f\"‚ùå Failed to import: {dashboard_name} ‚Äî Status: {response.status_code}\")\n",
    "                print(f\"Error Response: {response.text}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to import: {dashboard_name} ‚Äî Status: {response.status_code}\")\n",
    "            print(f\"Error Response: {response.text}\")\n",
    "            try:\n",
    "                error_json = response.json()\n",
    "                print(f\"Error Details: {json.dumps(error_json, indent=2)}\")\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Publish Dashboard with Warehouse\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì§ STEP 2: PUBLISHING DASHBOARD WITH WAREHOUSE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get available SQL warehouse\n",
    "warehouses_response = requests.get(\n",
    "    url=f\"{api_url}/api/2.0/sql/warehouses\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    ")\n",
    "\n",
    "warehouse_id = None\n",
    "if warehouses_response.status_code == 200:\n",
    "    warehouses = warehouses_response.json().get(\"warehouses\", [])\n",
    "    if warehouses:\n",
    "        # Get first running or stopped warehouse\n",
    "        for wh in warehouses:\n",
    "            if wh.get(\"state\") in [\"RUNNING\", \"STOPPED\"]:\n",
    "                warehouse_id = wh.get(\"id\")\n",
    "                warehouse_name = wh.get(\"name\")\n",
    "                print(f\"   üè≠ Found warehouse: {warehouse_name} ({warehouse_id})\")\n",
    "                break\n",
    "        if not warehouse_id:\n",
    "            # If none running/stopped, take the first one\n",
    "            warehouse_id = warehouses[0].get(\"id\")\n",
    "            warehouse_name = warehouses[0].get(\"name\")\n",
    "            print(f\"   üè≠ Using warehouse: {warehouse_name} ({warehouse_id})\")\n",
    "\n",
    "if warehouse_id:\n",
    "    # Publish dashboard with warehouse (using /published endpoint like in deploy_complete.py)\n",
    "    publish_response = requests.post(\n",
    "        url=f\"{api_url}/api/2.0/lakeview/dashboards/{dashboard_id}/published\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"},\n",
    "        json={\n",
    "            \"embed_credentials\": True,\n",
    "            \"warehouse_id\": warehouse_id\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if publish_response.status_code in [200, 201]:\n",
    "        print(f\"‚úÖ Dashboard published successfully\")\n",
    "        print(f\"   üè≠ Warehouse ID: {warehouse_id}\")\n",
    "        \n",
    "        # Verify the dashboard exists\n",
    "        verify_response = requests.get(\n",
    "            url=f\"{api_url}/api/2.0/lakeview/dashboards/{dashboard_id}\",\n",
    "            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "        )\n",
    "        \n",
    "        if verify_response.status_code == 200:\n",
    "            dashboard_info = verify_response.json()\n",
    "            verified_id = dashboard_info.get(\"dashboard_id\", \"\")\n",
    "            if verified_id == dashboard_id:\n",
    "                print(f\"   ‚úÖ Verified dashboard exists and is published\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Could not publish via API: {publish_response.status_code}\")\n",
    "        print(f\"   Response: {publish_response.text}\")\n",
    "        print(f\"   üìù Manual step: Open dashboard ‚Üí Click 'Publish' ‚Üí Select warehouse: {warehouse_id}\")\n",
    "        print(f\"   Dashboard URL: {api_url}/sql/dashboardsv3/{dashboard_id}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No warehouse found. Dashboard will be created but not published.\")\n",
    "    print(\"   You can publish it manually from the dashboard UI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Configure Embedding Domains (for Streamlit App)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîê STEP 3: CONFIGURING EMBEDDING DOMAINS\")\n",
    "print(\"=\"*70)\n",
    "print(\"   üìù Note: This allows the Streamlit app to embed the dashboard\")\n",
    "print(\"   üìù (Required for current app functionality, not related to Vector Search)\")\n",
    "\n",
    "embedding_domain = \"*.databricksapps.com\"\n",
    "embedding_response = requests.patch(\n",
    "    url=f\"{api_url}/api/2.0/lakeview/dashboards/{dashboard_id}\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"},\n",
    "    json={\"embedding_allowed_origins\": [embedding_domain]}\n",
    ")\n",
    "\n",
    "if embedding_response.status_code in [200, 201]:\n",
    "    print(f\"‚úÖ Added embedding domain: {embedding_domain}\")\n",
    "    print(f\"   ‚úÖ Streamlit app can now embed the dashboard\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Could not set via API: {embedding_response.status_code}\")\n",
    "    print(f\"üìù Manual step: Open dashboard ‚Üí Share ‚Üí Embed dashboard ‚Üí Add domain: {embedding_domain}\")\n",
    "    print(f\"   (This is required for the Streamlit app to display the dashboard)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Update App with Dashboard ID\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîÑ STEP 4: UPDATING APP WITH DASHBOARD ID\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract workspace ID from API URL\n",
    "workspace_id = api_url.split(\"/\")[2].split(\".\")[0].replace(\"dbc-\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "app_path = os.path.join(os.getcwd(), \"streamlit-waf-automation\", \"app.py\")\n",
    "\n",
    "try:\n",
    "    with open(app_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        app_content = f.read()\n",
    "    \n",
    "    # Update dashboard ID, instance URL, and workspace ID using regex\n",
    "    import re\n",
    "    app_content = re.sub(\n",
    "        r'DASHBOARD_ID = \"[^\"]+\"',\n",
    "        f'DASHBOARD_ID = \"{dashboard_id}\"',\n",
    "        app_content\n",
    "    )\n",
    "    app_content = re.sub(\n",
    "        r'INSTANCE_URL = \"[^\"]+\"',\n",
    "        f'INSTANCE_URL = \"{api_url}\"',\n",
    "        app_content\n",
    "    )\n",
    "    app_content = re.sub(\n",
    "        r'WORKSPACE_ID = \"[^\"]+\"',\n",
    "        f'WORKSPACE_ID = \"{workspace_id}\"',\n",
    "        app_content\n",
    "    )\n",
    "    \n",
    "    with open(app_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(app_content)\n",
    "    \n",
    "    print(f\"‚úÖ Updated app.py with dashboard ID\")\n",
    "    print(f\"   üìç Dashboard ID: {dashboard_id}\")\n",
    "    print(f\"   üìç Instance URL: {api_url}\")\n",
    "    print(f\"   üìç Workspace ID: {workspace_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error updating app.py: {e}\")\n",
    "    print(f\"   You may need to update app.py manually with:\")\n",
    "    print(f\"   DASHBOARD_ID = \\\"{dashboard_id}\\\"\")\n",
    "    print(f\"   INSTANCE_URL = \\\"{api_url}\\\"\")\n",
    "    print(f\"   WORKSPACE_ID = \\\"{workspace_id}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Deploy Databricks App\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STEP 5: DEPLOYING DATABRICKS APP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "app_name = \"waf-automation-tool\"\n",
    "workspace_path = f\"/Users/{user}/waf-app-source\"\n",
    "\n",
    "# Upload app files to workspace using Workspace API\n",
    "print(f\"üì§ Uploading app files to {workspace_path}...\")\n",
    "\n",
    "app_source_dir = os.path.join(os.getcwd(), \"streamlit-waf-automation\")\n",
    "\n",
    "# Create directory first\n",
    "mkdir_response = requests.post(\n",
    "    url=f\"{api_url}/api/2.0/workspace/mkdirs\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"},\n",
    "    json={\"path\": workspace_path}\n",
    ")\n",
    "\n",
    "# Upload each file\n",
    "import base64\n",
    "for item in os.listdir(app_source_dir):\n",
    "    source = os.path.join(app_source_dir, item)\n",
    "    if os.path.isfile(source):\n",
    "        dest_path = f\"{workspace_path}/{item}\"\n",
    "        \n",
    "        # Read file content\n",
    "        with open(source, \"rb\") as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Upload file\n",
    "        upload_response = requests.post(\n",
    "            url=f\"{api_url}/api/2.0/workspace/import\",\n",
    "            headers={\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"},\n",
    "            json={\n",
    "                \"path\": dest_path,\n",
    "                \"content\": base64.b64encode(content).decode(\"utf-8\"),\n",
    "                \"format\": \"AUTO\",\n",
    "                \"language\": \"PYTHON\" if item.endswith(\".py\") else \"AUTO\",\n",
    "                \"overwrite\": True\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if upload_response.status_code in [200, 201]:\n",
    "            print(f\"   ‚úÖ Uploaded: {item}\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Failed to upload {item}: {upload_response.status_code}\")\n",
    "\n",
    "print(f\"‚úÖ App files uploaded to {workspace_path}\")\n",
    "\n",
    "# Deploy app using Databricks CLI (like in deploy_complete.py)\n",
    "print(f\"\\nüì¶ Deploying app: {app_name}\")\n",
    "print(f\"   üìÅ Source path: /Workspace{workspace_path}\")\n",
    "\n",
    "# Use dbutils to run shell command for app deployment\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Set environment variable to skip TLS verification (if needed)\n",
    "env = os.environ.copy()\n",
    "env['DATABRICKS_INSECURE_TLS_SKIP_VERIFY'] = 'true'\n",
    "\n",
    "# Deploy app using CLI\n",
    "deploy_cmd = f'databricks apps deploy {app_name} --source-code-path /Workspace{workspace_path}'\n",
    "result = subprocess.run(\n",
    "    deploy_cmd,\n",
    "    shell=True,\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    env=env\n",
    ")\n",
    "\n",
    "app_url = None\n",
    "if result.returncode == 0:\n",
    "    print(f\"‚úÖ App deployed successfully\")\n",
    "    try:\n",
    "        # Try to parse deployment ID from output\n",
    "        output_json = json.loads(result.stdout)\n",
    "        deployment_id = output_json.get(\"deployment_id\", \"\")\n",
    "        if deployment_id:\n",
    "            print(f\"   üÜî Deployment ID: {deployment_id}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Get app URL\n",
    "    get_app_cmd = f'databricks apps get {app_name} --output json'\n",
    "    app_result = subprocess.run(\n",
    "        get_app_cmd,\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        env=env\n",
    "    )\n",
    "    \n",
    "    if app_result.returncode == 0:\n",
    "        try:\n",
    "            app_info = json.loads(app_result.stdout)\n",
    "            app_url = app_info.get(\"url\", \"\")\n",
    "            if app_url:\n",
    "                print(f\"   üöÄ App URL: {app_url}\")\n",
    "        except:\n",
    "            pass\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Error deploying app via CLI: {result.stderr}\")\n",
    "    print(f\"   üìù Manual deployment steps:\")\n",
    "    print(f\"   1. Go to Databricks Apps: {api_url}/apps\")\n",
    "    print(f\"   2. Click 'Create App' or 'Deploy App'\")\n",
    "    print(f\"   3. App name: {app_name}\")\n",
    "    print(f\"   4. Source code path: /Workspace{workspace_path}\")\n",
    "    print(f\"   5. Click 'Deploy'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ INSTALLATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Dashboard ID: {dashboard_id}\")\n",
    "print(f\"üîó Dashboard URL: {api_url}/sql/dashboardsv3/{dashboard_id}\")\n",
    "if warehouse_id:\n",
    "    print(f\"üè≠ Warehouse ID: {warehouse_id}\")\n",
    "if 'app_url' in locals() and app_url:\n",
    "    print(f\"üöÄ App URL: {app_url}\")\n",
    "print(f\"\\nüí° Next Steps:\")\n",
    "print(f\"   1. ‚úÖ Dashboard created: {api_url}/sql/dashboardsv3/{dashboard_id}\")\n",
    "print(f\"   2. üìù Publish dashboard (if not done automatically):\")\n",
    "print(f\"      - Open dashboard ‚Üí Click 'Publish' ‚Üí Select warehouse\")\n",
    "print(f\"   3. üìù Deploy app (manual step required):\")\n",
    "print(f\"      - Go to {api_url}/apps ‚Üí Create/Deploy App\")\n",
    "print(f\"      - Source path: /Workspace/Users/{user}/waf-app-source\")\n",
    "print(f\"   4. ‚úÖ Embedding domain already configured: *.databricksapps.com\")\n",
    "print(f\"   5. üîó After app deployment, open the app URL to verify dashboard loads\")\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   Dashboard ID: {dashboard_id}\")\n",
    "if warehouse_id:\n",
    "    print(f\"   Warehouse ID: {warehouse_id}\")\n",
    "print(f\"   App source: /Workspace/Users/{user}/waf-app-source\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "install",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
