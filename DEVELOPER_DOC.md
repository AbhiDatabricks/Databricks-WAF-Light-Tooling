# WAF Dashboard - Developer Documentation

## Overview

The WAF Assessment Dashboard uses a **consistent 3-dataset pattern** for each of the 4 pillars (Reliability, Governance, Cost Optimization, Performance Efficiency), plus a **Summary dataset** that aggregates across all pillars.

---

## ðŸ“Š Dataset Architecture

### Dataset Pattern (Per Pillar)

Each pillar follows the same 3-dataset structure:

1. **`total_percentage_[pillar]`** - Overall completion percentage (1 row)
2. **`waf_controls_[pillar]`** - Individual metrics with scores (N rows, one per metric)
3. **`waf_principal_percentage_[pillar]`** - Completion per principle (M rows, one per principle)

### Summary Dataset

- **`total_percentage_across_pillars`** - Aggregates scores from all 4 pillars (4 rows, one per pillar)

---

## ðŸ—ï¸ Complete Dataset List

| Pillar | Dataset Name | Display Name | Dataset ID | Purpose |
|--------|-------------|--------------|------------|---------|
| **Reliability (R)** | `total_percentage_r` | total_percentage_r | `03babf4f` | Overall Reliability completion % |
| | `waf_controls_r` | waf_controls_r | `60cfe928` | Individual Reliability metrics |
| | `waf_principal_percentage_r` | waf_principal_percentage_r | `011cf80a` | Reliability completion per principle |
| **Governance (G)** | `total_percentage_g` | total_percentage_g | `920a8759` | Overall Governance completion % |
| | `waf_controls_g` | waf_controls_g | `1eab9fe1` | Individual Governance metrics |
| | `waf_principal_percentage_g` | waf_principal_percentage_g | `95258030` | Governance completion per principle |
| **Cost Optimization (C)** | `total_percentage_c` | total_percentage_c | `06f2987c` | Overall Cost completion % |
| | `waf_controls_c` | waf_controls_c | `dbdc9433` | Individual Cost metrics |
| | `waf_principal_percentage_c` | waf_principal_percentage_c | `81f0a6aa` | Cost completion per principle |
| **Performance Efficiency (P)** | `total_percentage_p` | total_percentage_p | `87deca0d` | Overall Performance completion % |
| | `waf_controls_p` | waf_controls_p | `4745a0f9` | Individual Performance metrics |
| | `waf_principal_percentage_p` | waf_principal_percentage_p | `13e29e6c` | Performance completion per principle |
| **Summary** | `total_percentage_across_pillars` | total_percentage_across_pillars | `b39d7f91` | Aggregated scores from all pillars |

---

## ðŸ”— Dataset Relationships

### 1. Within Each Pillar (3-Dataset Pattern)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              total_percentage_[pillar]                  â”‚
â”‚              (Overall completion: 1 row)                  â”‚
â”‚                                                          â”‚
â”‚  Example: total_percentage_r = 38%                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        Aggregates all metrics in the pillar
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚waf_controls_  â”‚ â”‚waf_principal_    â”‚ â”‚  (Same base      â”‚
â”‚[pillar]       â”‚ â”‚percentage_[pillar]â”‚ â”‚   calculations)  â”‚
â”‚               â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ N rows        â”‚ â”‚ M rows           â”‚ â”‚  Shared CTEs:    â”‚
â”‚ (one per      â”‚ â”‚ (one per         â”‚ â”‚  - metric_1     â”‚
â”‚  metric)      â”‚ â”‚  principle)      â”‚ â”‚  - metric_2     â”‚
â”‚               â”‚ â”‚                  â”‚ â”‚  - metric_3     â”‚
â”‚ Individual    â”‚ â”‚ Principle-level  â”‚ â”‚  - ...           â”‚
â”‚ scores,       â”‚ â”‚ completion       â”‚ â”‚                  â”‚
â”‚ thresholds,   â”‚ â”‚                  â”‚ â”‚                  â”‚
â”‚ status        â”‚ â”‚                  â”‚ â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Across All Pillars (Summary Aggregation)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         total_percentage_across_pillars                 â”‚
â”‚         (Summary: 4 rows, one per pillar)               â”‚
â”‚                                                          â”‚
â”‚  pillar          | completion_percent                    â”‚
â”‚  ----------------|-------------------                    â”‚
â”‚  Reliability     | 38                                   â”‚
â”‚  Governance      | 65                                   â”‚
â”‚  Cost            | 45                                   â”‚
â”‚  Performance     | 72                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    Aggregates from individual pillar totals
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚               â”‚
    â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚total_    â”‚  â”‚total_    â”‚  â”‚total_    â”‚  â”‚total_    â”‚
â”‚percentageâ”‚  â”‚percentageâ”‚  â”‚percentageâ”‚  â”‚percentageâ”‚
â”‚_r        â”‚  â”‚_g        â”‚  â”‚_c        â”‚  â”‚_p        â”‚
â”‚          â”‚  â”‚          â”‚  â”‚          â”‚  â”‚          â”‚
â”‚38%       â”‚  â”‚65%       â”‚  â”‚45%       â”‚  â”‚72%       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“‹ Dataset Structure Details

### Pattern 1: `total_percentage_[pillar]`

**Purpose**: Calculate overall completion percentage for the pillar

**Output Structure** (1 row):
```sql
total_controls | implemented_controls | completion_percent
--------------|----------------------|-------------------
      8       |          3           |        38
```

**Logic**:
- Evaluates all metrics in the pillar
- Counts how many have `implemented = 'Pass'` (or `'Yes'` in older versions)
- Calculates: `(implemented_controls / total_controls) Ã— 100`

**Used For**:
- Main completion percentage display at top of pillar page
- Summary tab aggregation

---

### Pattern 2: `waf_controls_[pillar]`

**Purpose**: Show detailed breakdown of each individual metric

**Output Structure** (N rows - one per metric):
```sql
waf_id  | principle              | best_practice              | score_percentage | threshold_percentage | threshold_met | implemented
--------|------------------------|----------------------------|------------------|---------------------|---------------|-------------
R-01-01 | Design for failure     | Use Delta format...        | 85.5             | 80                  | Met           | Pass
R-01-03 | Design for failure     | Use DLT for data quality   | 25.0             | 30                  | Not Met       | Fail
...
```

**Columns**:
- `waf_id`: WAF identifier (e.g., R-01-01, G-02-03)
- `principle`: WAF principle name
- `best_practice`: Description of the best practice
- `score_percentage`: Actual calculated percentage for this metric
- `threshold_percentage`: Required threshold to pass
- `threshold_met`: 'Met' or 'Not Met'
- `implemented`: 'Pass' or 'Fail' (was 'Yes'/'No' in older versions)

**Logic**:
- Shows all metrics individually
- Calculates actual percentage for each metric using percentage-based logic
- Compares against threshold to determine `implemented` status
- Provides threshold reference for each metric

**Used For**:
- Detailed "WAF Controls Table" chart
- Users can see which specific metrics need improvement
- Conditional formatting (red rows for unmet thresholds)

---

### Pattern 3: `waf_principal_percentage_[pillar]`

**Purpose**: Calculate completion percentage grouped by principle

**Output Structure** (M rows - one per principle):
```sql
principle              | total_controls | implemented_controls | completion_percent
-----------------------|----------------|----------------------|-------------------
Design for failure     |       4        |          2           |        50
Manage data quality    |       2        |          1           |        50
Design for autoscaling |       2        |          1           |        50
```

**Logic**:
- Groups metrics by their principle
- Counts total and implemented per principle
- Calculates: `(implemented_controls / total_controls) Ã— 100` per principle

**Used For**:
- "Completion percentage of implemented controls per principle" chart
- Shows which principles need more attention
- Helps prioritize improvement efforts

---

### Pattern 4: `total_percentage_across_pillars` (Summary)

**Purpose**: Aggregate scores from all four pillars

**Output Structure** (4 rows - one per pillar):
```sql
pillar          | completion_percent
----------------|-------------------
Reliability     | 38
Governance      | 65
Cost            | 45
Performance     | 72
```

**Logic**:
- Queries each pillar's `total_percentage_[pillar]` dataset
- Extracts the `completion_percent` value
- Combines into a single result set with pillar names

**SQL Pattern**:
```sql
SELECT 'Reliability' as pillar, completion_percent 
FROM total_percentage_r
UNION ALL
SELECT 'Governance' as pillar, completion_percent 
FROM total_percentage_g
UNION ALL
SELECT 'Cost' as pillar, completion_percent 
FROM total_percentage_c
UNION ALL
SELECT 'Performance' as pillar, completion_percent 
FROM total_percentage_p
```

**Used For**:
- Summary tab showing all pillar scores
- Overall WAF assessment view
- Comparison across pillars

---

## ðŸ”„ Data Flow and Dependencies

### Calculation Flow

```
1. System Tables (Data Sources)
   â†“
2. Shared CTEs (Common Calculations)
   - delta_usage
   - dlt_usage
   - serverless_usage
   - photon_usage
   - cluster_metrics
   - warehouse_metrics
   - table_metrics
   - etc.
   â†“
3. Individual Metric Evaluation
   - Each metric calculated with percentage-based logic
   - Threshold comparison
   - Pass/Fail determination
   â†“
4. Aggregation (3 different views)
   â”œâ”€â”€ waf_controls_[pillar] (detailed, no aggregation)
   â”œâ”€â”€ waf_principal_percentage_[pillar] (GROUP BY principle)
   â””â”€â”€ total_percentage_[pillar] (aggregate all)
   â†“
5. Summary Aggregation
   â””â”€â”€ total_percentage_across_pillars (UNION ALL from all pillars)
```

### Consistency Guarantees

All three datasets within a pillar:
- âœ… Use the same CTEs (shared calculations)
- âœ… Evaluate the same metrics
- âœ… Use the same thresholds
- âœ… Use the same percentage-based logic
- âœ… Will always show consistent results

This ensures:
- The overall percentage matches the sum of individual metrics
- Principle percentages match the metrics within them
- No discrepancies between different views
- Summary tab correctly aggregates from individual pillars

---

## ðŸ“ Hierarchical Structure Example (Reliability)

```
total_percentage_r (38%)
â”‚
â”œâ”€â”€ Design for failure (50%)
â”‚   â”œâ”€â”€ R-01-01: Delta format (85.5%) âœ… Pass
â”‚   â”œâ”€â”€ R-01-03: DLT usage (25.0%) âŒ Fail
â”‚   â”œâ”€â”€ R-01-05: Model Serving (15.0%) âŒ Fail
â”‚   â””â”€â”€ R-01-06: Serverless/Managed (60.0%) âœ… Pass
â”‚
â”œâ”€â”€ Manage data quality (50%)
â”‚   â”œâ”€â”€ R-02-03: Unity Catalog (100.0%) âœ… Pass
â”‚   â””â”€â”€ R-02-04: DLT for data quality (25.0%) âŒ Fail
â”‚
â””â”€â”€ Design for autoscaling (50%)
    â”œâ”€â”€ R-03-01: Auto-scaling clusters (75.0%) âŒ Fail
    â””â”€â”€ R-03-02: Auto-scaling warehouses (90.0%) âœ… Pass
```

**Mathematical Relationship**:
- `total_percentage_r.completion_percent` = Weighted average of `waf_principal_percentage_r.completion_percent`
- Each principle contributes based on number of metrics it contains
- Individual metrics in `waf_controls_r` roll up to principles in `waf_principal_percentage_r`
- Principles roll up to overall in `total_percentage_r`

---

## ðŸŽ¯ Usage in Dashboard Widgets

### Summary Tab
- **Widget**: "Completion percentage across pillars"
- **Dataset**: `total_percentage_across_pillars`
- **Shows**: Bar chart with all 4 pillar scores

### Pillar Pages (Reliability, Governance, Cost, Performance)

Each pillar page has 3 widgets:

1. **Top Widget**: Overall completion percentage
   - **Dataset**: `total_percentage_[pillar]`
   - **Shows**: Single number or gauge

2. **Middle Widget**: Completion per principle
   - **Dataset**: `waf_principal_percentage_[pillar]`
   - **Shows**: Bar chart grouped by principle

3. **Bottom Widget**: WAF Controls Table
   - **Dataset**: `waf_controls_[pillar]`
   - **Shows**: Table with all metrics, scores, thresholds, and status
   - **Formatting**: Red rows for unmet thresholds

---

## ðŸ”§ Implementation Details

### Percentage-Based Logic

All metrics use **percentage-based calculations** instead of simple EXISTS checks:

**Old Approach (Removed)**:
```sql
CASE WHEN EXISTS (SELECT 1 FROM ...) THEN 100 ELSE 0 END
```

**New Approach (Current)**:
```sql
CASE 
  WHEN total_count > 0 THEN (passing_count * 100.0 / total_count)
  ELSE 0 
END
```

**Example**: Delta format usage
- **Old**: "Do you have ANY Delta tables?" â†’ 100% or 0%
- **New**: "What % of your tables are Delta?" â†’ 0-100% based on actual usage

### Threshold-Based Pass/Fail

Each metric has a threshold:
- **Pass**: `score_percentage >= threshold_percentage`
- **Fail**: `score_percentage < threshold_percentage`

**Example**:
- R-01-01: Delta format â‰¥80% â†’ Pass
- R-01-03: DLT usage â‰¥30% â†’ Pass
- R-01-05: Model Serving â‰¥20% â†’ Pass

### Shared CTEs Pattern

All three datasets in a pillar share the same CTEs to ensure consistency:

```sql
WITH shared_cte_1 AS (...),
     shared_cte_2 AS (...),
     shared_cte_3 AS (...)
SELECT ...
FROM (
  SELECT * FROM VALUES
    ('WAF-ID-1', 'Principle 1', 'Best Practice 1'),
    ('WAF-ID-2', 'Principle 1', 'Best Practice 2'),
    ...
  AS waf(waf_id, principle, best_practice)
)
```

---

## ðŸ› Troubleshooting

### Issue: Summary score doesn't match individual pillar

**Check**:
1. Verify `total_percentage_across_pillars` queries each pillar's `total_percentage_[pillar]`
2. Ensure pillar names match exactly ('Reliability', 'Governance', 'Cost', 'Performance')
3. Check for NULL values in completion_percent

### Issue: Principle percentage doesn't match individual metrics

**Check**:
1. Verify `waf_principal_percentage_[pillar]` groups by the same `principle` field
2. Ensure all metrics in `waf_controls_[pillar]` have valid principle values
3. Check that `implemented` logic is consistent (Pass/Fail)

### Issue: Overall percentage doesn't match principle breakdown

**Check**:
1. Verify all three datasets use the same CTEs
2. Ensure threshold logic is identical
3. Check for rounding differences (use ROUND consistently)

### Issue: Dashboard shows old data

**Check**:
1. Verify SQL warehouse is running
2. Check dataset refresh settings
3. Ensure queries are not cached (add timestamp if needed)

---

## ðŸ“ Best Practices

1. **Always update all 3 datasets together** when modifying a pillar
2. **Use shared CTEs** to ensure consistency
3. **Test all 3 datasets** after changes to verify consistency
4. **Document threshold changes** in code comments
5. **Use percentage-based logic** for all metrics (not EXISTS checks)
6. **Maintain consistent naming** across datasets (total_percentage, waf_controls, waf_principal_percentage)
7. **Verify Summary aggregation** after pillar changes

---

## ðŸ”„ Migration Notes

### From Yes/No to Pass/Fail

**Changed**: `implemented` column values
- **Old**: 'Yes' / 'No'
- **New**: 'Pass' / 'Fail'

**Updated in**: All `waf_controls_[pillar]` datasets

### From EXISTS to Percentage-Based

**Changed**: Metric evaluation logic
- **Old**: Simple EXISTS checks (binary 0% or 100%)
- **New**: Percentage-based calculations (0-100% based on actual usage)

**Benefits**:
- More accurate scoring
- Better reflects actual adoption
- Stricter thresholds (e.g., â‰¥80% instead of "any")

---

## ðŸ“š Related Documentation

- **RELIABILITY_DATASETS_RELATIONSHIP.md** - Detailed Reliability pillar documentation
- **RELIABILITY_METRICS_DOCUMENTATION.md** - Reliability metrics and calculations
- **WAF_DASHBOARD_GUIDE.md** - User-facing guide
- **USER_GUIDE.md** - End-user documentation

---

## ðŸŽ“ Summary

The WAF Dashboard uses a **consistent, hierarchical dataset structure**:

1. **13 total datasets**: 3 per pillar (Ã—4) + 1 summary
2. **3-level hierarchy**: Overall â†’ Principles â†’ Individual Metrics
3. **Consistent logic**: Shared CTEs ensure all views are aligned
4. **Percentage-based**: All metrics use actual usage percentages
5. **Threshold-driven**: Clear Pass/Fail criteria for each metric

This architecture ensures:
- âœ… Accurate scoring
- âœ… Consistent views
- âœ… Easy maintenance
- âœ… Clear user experience

---

**Last Updated**: February 2026  
**Dashboard Version**: v1.6  
**Maintained By**: WAF Assessment Team
