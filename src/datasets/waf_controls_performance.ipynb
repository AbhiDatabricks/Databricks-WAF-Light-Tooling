{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8aedc0aa-0c0a-4191-a1cf-0d47b99c8260",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "WITH PE_01 AS (\n",
    "SELECT \n",
    "    billing_origin_product\n",
    "  , SUM(runs) AS runs_total\n",
    "  , SUM(dbu_usage) AS dbu_usage_total\n",
    "  , 'PE_01' AS waf_id\n",
    "  , 'Detailed' AS dataset_type\n",
    "  , SUM(CASE WHEN is_serverless = true THEN runs ELSE 0 END) AS sum_serverless_run\n",
    "  , SUM(CASE WHEN is_serverless = true THEN dbu_usage ELSE 0 END) AS sum_serverless_dbu\n",
    "  , SUM(CASE WHEN is_serverless = false THEN runs ELSE 0 END) AS sum_non_serverless_run\n",
    "  , SUM(CASE WHEN is_serverless = false THEN dbu_usage ELSE 0 END) AS sum_non_serverless_dbu\n",
    "  , SUM(CASE WHEN is_serverless = true THEN runs ELSE 0 END)/SUM(runs) AS pct_serverless_runs\n",
    "  , SUM(CASE WHEN is_serverless = true THEN dbu_usage ELSE 0 END)/SUM(dbu_usage) AS pct_serverless_dbu\n",
    "FROM \n",
    "(SELECT \n",
    "   COUNT(*) AS runs\n",
    "  ,SUM(usage_quantity) AS dbu_usage, CASE WHEN billing_origin_product = 'ALL_PURPOSE' THEN 'INTERACTIVE' ELSE billing_origin_product END AS billing_origin_product\n",
    "  , CASE WHEN sku_name LIKE '%SERVERLESS%' OR product_features.is_serverless = true THEN true ELSE false END AS is_serverless\n",
    " FROM system.billing.usage \n",
    " WHERE usage_date BETWEEN :date_filter.min AND :date_filter.max\n",
    " AND array_contains(:workspace_id,workspace_id)\n",
    " AND usage_unit = 'DBU'\n",
    " AND billing_origin_product IN ('JOBS','MODEL_SERVING','LAKEFLOW_CONNECT','SQL','INTERACTIVE','DLT','ALL_PURPOSE')\n",
    " GROUP BY CASE WHEN billing_origin_product = 'ALL_PURPOSE' THEN 'INTERACTIVE' ELSE billing_origin_product END, CASE WHEN sku_name LIKE '%SERVERLESS%' OR product_features.is_serverless = true THEN true ELSE false END \n",
    ")CTE\n",
    "GROUP BY\n",
    "billing_origin_product \n",
    "),\n",
    "PE_01_01_perc AS (\n",
    "  SELECT \n",
    "    ROUND((SUM(sum_serverless_dbu)/SUM(dbu_usage_total))*100,2) AS actual_perc,\n",
    "    'PE-01-01' AS waf_id,\n",
    "    'Percentage' AS dataset_type\n",
    "  FROM PE_01\n",
    "  WHERE billing_origin_product <> 'MODEL_SERVING'\n",
    "),\n",
    "--waf_PE-02-*_cluster_metrics\n",
    "usage AS (    \n",
    "  SELECT usage_metadata.cluster_id AS cluster_id, account_id, workspace_id\n",
    "  , count(*) as runs, SUM(usage_quantity) AS dbu_usage FROM system.billing.usage \n",
    "    WHERE \n",
    "     usage_date BETWEEN :date_filter.min AND :date_filter.max\n",
    "     AND array_contains(:workspace_id,workspace_id)\n",
    "    AND usage_metadata.cluster_id IS NOT NULL\n",
    "    GROUP BY account_id, workspace_id, usage_metadata.cluster_id\n",
    "),\n",
    "compute_met AS (\n",
    "  SELECT * FROM \n",
    "    (select  row_number() over(partition by account_id, workspace_id, cluster_id order by change_time desc) AS rn\n",
    "        , account_id, workspace_id, c.cluster_id, c.cluster_name, c.worker_node_type, worker_count, max_autoscale_workers, min_autoscale_workers\n",
    "    from system.compute.clusters c \n",
    "    WHERE array_contains(:workspace_id,workspace_id)\n",
    "    AND change_date <= :date_filter.max) --TBD to check this filter\n",
    "    WHERE rn = 1\n",
    "),\n",
    "PE_02 AS (\n",
    "  SELECT \n",
    "       *\n",
    "      , row_number() over( order by dbu_usage desc) AS rank\n",
    "      , 'PE_02' AS waf_id\n",
    "      , 'Detailed' AS dataset_type\n",
    "    FROM(\n",
    "      SELECT SUM(u.dbu_usage) AS dbu_usage, SUM(u.runs) AS runs, c.cluster_id, c.cluster_name, c.worker_node_type\n",
    "            ,CASE WHEN ifnull(worker_count,ifnull(max_autoscale_workers,0)) > 1 THEN 'Multi-Node' ELSE 'Single-Node' END AS is_multi_worker\n",
    "            , ifnull(worker_count,ifnull(max_autoscale_workers,0)) AS max_worker_count\n",
    "            , CASE WHEN ifnull(c.min_autoscale_workers,0) = ifnull(c.max_autoscale_workers,0) THEN 0 ELSE 1 END AS is_autoscaling\n",
    "      FROM\n",
    "      usage u\n",
    "      INNER JOIN\n",
    "      compute_met c\n",
    "      ON u.cluster_id = c.cluster_id\n",
    "      AND u.account_id = c.account_id\n",
    "      AND u.workspace_id = c.workspace_id\n",
    "      GROUP BY\n",
    "      c.cluster_id, c.cluster_name, c.worker_node_type\n",
    "      ,CASE WHEN ifnull(worker_count,ifnull(max_autoscale_workers,0)) > 1 THEN 'Multi-Node' ELSE 'Single-Node' END\n",
    "      , ifnull(worker_count,ifnull(max_autoscale_workers,0)) \n",
    "      , CASE WHEN ifnull(c.min_autoscale_workers,0) = ifnull(c.max_autoscale_workers,0) THEN 0 ELSE 1 END \n",
    "    )\n",
    "),\n",
    "PE_02_02_perc AS (\n",
    "  SELECT \n",
    "    ROUND((SUM(CASE WHEN is_multi_worker = 'Multi-Node' THEN 1 ELSE 0 END)/COUNT(*))*100,2) AS actual_perc,\n",
    "    'PE-02-02' AS waf_id\n",
    "    , 'Percentage' AS dataset_type\n",
    "  FROM PE_02\n",
    "),\n",
    "PE_02_04_perc AS (\n",
    "  SELECT \n",
    "    ROUND((SUM(CASE WHEN max_worker_count > 3 THEN 1 ELSE 0 END)/COUNT(*))*100,2) AS actual_perc,\n",
    "    'PE-02-04' AS waf_id\n",
    "    , 'Percentage' AS dataset_type\n",
    "  FROM PE_02\n",
    "),\n",
    "PE_02_05 AS (\n",
    "  SELECT \n",
    "    'PE_02_05' AS waf_id,\n",
    "    'Detailed' AS dataset_type,\n",
    "    COUNT(*) as count_routines\n",
    "  FROM system.information_schema.routines WHERE external_language = 'Python' \n",
    "),\n",
    "\n",
    "PE_02_06 AS (\n",
    "  SELECT \n",
    "    'PE_02_06' AS waf_id\n",
    "  , 'Detailed' AS dataset_type\n",
    "  , billing_origin_product\n",
    "  , SUM(runs) AS runs_total\n",
    "  , SUM(dbu_usage) AS dbu_usage_total\n",
    "  , SUM(CASE WHEN is_photon = true THEN runs ELSE 0 END) AS sum_photon_run\n",
    "  , SUM(CASE WHEN is_photon = true THEN dbu_usage ELSE 0 END) AS sum_photon_dbu\n",
    "  , SUM(CASE WHEN is_photon = false THEN runs ELSE 0 END) AS sum_non_photon_run\n",
    "  , SUM(CASE WHEN is_photon = false THEN dbu_usage ELSE 0 END) AS sum_non_photon_dbu\n",
    "  , SUM(CASE WHEN is_photon = true THEN runs ELSE 0 END)/SUM(runs) AS pct_photon_runs\n",
    "  , SUM(CASE WHEN is_photon = true THEN dbu_usage ELSE 0 END)/SUM(dbu_usage) AS pct_photon_dbu\n",
    "  FROM (\n",
    "    SELECT COUNT(*) AS runs,SUM(usage_quantity) AS dbu_usage, billing_origin_product\n",
    "    , CASE WHEN sku_name LIKE '%PHOTON%' OR product_features.is_photon = true THEN true ELSE false END AS is_photon\n",
    "    FROM system.billing.usage \n",
    "    WHERE usage_date BETWEEN :date_filter.min AND :date_filter.max\n",
    "    AND array_contains(:workspace_id,workspace_id)\n",
    "    AND billing_origin_product  IN ('JOBS','LAKEFLOW_CONNECT','VECTOR_SEARCH','DATABASE','DLT','ALL_PURPOSE','ONLINE_TABLES','INTERACTIVE')\n",
    "    AND usage_unit = 'DBU'\n",
    "    GROUP BY billing_origin_product, CASE WHEN sku_name LIKE '%PHOTON%' OR product_features.is_photon = true THEN true ELSE false END \n",
    ")\n",
    "GROUP BY\n",
    "billing_origin_product \n",
    "),\n",
    "PE_02_06_perc AS \n",
    "(\n",
    "  SELECT \n",
    "    ROUND((SUM(sum_photon_dbu)/SUM(dbu_usage_total))*100,2) AS actual_perc,\n",
    "    'PE-02-06' AS waf_id,\n",
    "    'Percentage' AS dataset_type\n",
    "  FROM PE_02_06\n",
    "),\n",
    "PE_02_07_perc AS \n",
    "(\n",
    "  SELECT \n",
    "    ROUND((COUNT(DISTINCT split(worker_node_type,'[.]')[0])/COUNT(1))*100,2) AS actual_perc,\n",
    "    'PE-02-07' AS waf_id,\n",
    "    'Percentage' AS dataset_type\n",
    "  FROM PE_02\n",
    "),\n",
    "\n",
    "\n",
    "waf_status AS(\n",
    "SELECT\n",
    "  waf.waf_id,\n",
    "  principle,\n",
    "  best_practice,\n",
    "  COALESCE(p11p.actual_perc,p22p.actual_perc,p24p.actual_perc,p26p.actual_perc,p27p.actual_perc,0.00) AS actual_perc,\n",
    "  CASE \n",
    "    WHEN waf.waf_id = 'PE-01-02' AND EXISTS (\n",
    "      SELECT 1 FROM PE_01 WHERE billing_origin_product = 'MODEL_SERVING' LIMIT 1\n",
    "    ) THEN 'Yes' --TBD dbu usage limit?\n",
    "    WHEN waf.waf_id = 'PE-02-05' AND NOT EXISTS (\n",
    "      SELECT 1 FROM PE_02_05 LIMIT 1 \n",
    "    ) THEN 'Yes'\n",
    "    WHEN waf.waf_id NOT IN ('PE-01-02','PE-02-05') \n",
    "          AND  required_percentage <= COALESCE(p11p.actual_perc,p22p.actual_perc,p24p.actual_perc,p26p.actual_perc,p27p.actual_perc,0) THEN 'Yes'\n",
    "    ELSE 'No'\n",
    "  END AS implemented,\n",
    "  required_percentage\n",
    "FROM (\n",
    "  SELECT * FROM VALUES\n",
    "    ('PE-01-01', 'Utilize serverless capabilities', 'Use serverless architecture',30),\n",
    "    ('PE-01-02', 'Utilize serverless capabilities', 'Use an enterprise grade model serving service',0),\n",
    "    --('PE-02-01', 'Utilize serverless capabilities', 'Understand your data ingestion and access patterns'),\n",
    "    ('PE-02-02', 'Design workloads for performance', 'Use parallel computation where it is beneficial',30),\n",
    "    --('PE-02-03', 'Design workloads for performance', 'Analyze the whole chain of execution'),\n",
    "    ('PE-02-04', 'Design workloads for performance', 'Prefer larger clusters',30),\n",
    "    ('PE-02-05', 'Design workloads for performance', 'Use native Spark operations',0),\n",
    "    ('PE-02-06', 'Design workloads for performance', 'Use native platform engines',30),\n",
    "    ('PE-02-07', 'Design workloads for performance', 'Understand your hardware and workload type',20)\n",
    "    --('PE-02-08', 'Design workloads for performance', 'Use caching'),\n",
    "    --('PE-02-09', 'Design workloads for performance', 'Use compaction'),\n",
    ") waf(waf_id, principle, best_practice,required_percentage)\n",
    "LEFT JOIN \n",
    "PE_01_01_perc p11p\n",
    "ON waf.waf_id = p11p.waf_id\n",
    "LEFT JOIN \n",
    "PE_02_02_perc p22p\n",
    "ON waf.waf_id = p22p.waf_id\n",
    "LEFT JOIN\n",
    "PE_02_04_perc p24p\n",
    "ON waf.waf_id = p24p.waf_id\n",
    "LEFT JOIN\n",
    "PE_02_06_perc p26p\n",
    "ON waf.waf_id = p26p.waf_id\n",
    "LEFT JOIN\n",
    "PE_02_07_perc p27p\n",
    "ON waf.waf_id = p27p.waf_id\n",
    ")\n",
    "SELECT\n",
    "  waf_id,\n",
    "  principle,\n",
    "  best_practice,\n",
    "  implemented,\n",
    "  actual_perc,\n",
    "  required_percentage,\n",
    "  COUNT(*) OVER (PARTITION BY principle) AS total_controls,\n",
    "  ROW_NUMBER() OVER (PARTITION BY principle ORDER BY waf_id) AS row_num,\n",
    "  SUM(CASE WHEN implemented = 'Yes' THEN 1 ELSE 0 END) OVER (PARTITION BY principle) AS implemented_controls,\n",
    "  ROUND(100 * SUM(CASE WHEN implemented = 'Yes' THEN 1 ELSE 0 END) OVER (PARTITION BY principle)/ COUNT(*) OVER (PARTITION BY principle) , 0) AS completion_percent,\n",
    "  ROUND(100 * SUM(CASE WHEN implemented = 'Yes' THEN 1 ELSE 0 END) OVER () / COUNT(*) OVER (), 0) AS total_percentage,\n",
    "  'Summary' AS dataset_type,\n",
    "  '' AS billing_origin_product,\n",
    "  0 AS runs_total,\n",
    "  0 AS dbu_usage_total, \n",
    "  0 AS sum_serverless_run,\n",
    "  0 AS sum_serverless_dbu,\n",
    "  0 AS sum_non_serverless_run,\n",
    "  0 AS sum_non_serverless_dbu,\n",
    "  0 AS pct_serverless_runs,\n",
    "  0 AS pct_serverless_dbu,\n",
    "  '' AS cluster_id,\n",
    "  '' AS cluster_name,\n",
    "  '' AS worker_node_type,\n",
    "  '' AS is_multi_worker,\n",
    "  '' AS max_worker_count,\n",
    "  '' AS is_autoscaling,\n",
    "  '' AS rank,\n",
    "  0 AS count_routines,\n",
    "  0 AS sum_photon_run,\n",
    "  0 AS sum_photon_dbu,\n",
    "  0 AS sum_non_photon_run,\n",
    "  0 AS sum_non_photon_dbu,\n",
    "  0 AS pct_photon_runs,\n",
    "  0 AS pct_photon_dbu\n",
    "FROM waf_status\n",
    "UNION ALL\n",
    "SELECT\n",
    "  waf_id,\n",
    "  '' AS principle,\n",
    "  '' AS best_practice,\n",
    "  '' AS implemented,\n",
    "  0 AS actual_perc,\n",
    "  0 AS required_percentage,\n",
    "  0 AS total_controls,\n",
    "  0 AS row_num,\n",
    "  0 AS implemented_controls,\n",
    "  0 AS completion_percent,\n",
    "  0 AS total_percentage,\n",
    "  dataset_type,\n",
    "  billing_origin_product,\n",
    "  runs_total,\n",
    "  dbu_usage_total, \n",
    "  sum_serverless_run,\n",
    "  sum_serverless_dbu,\n",
    "  sum_non_serverless_run,\n",
    "  sum_non_serverless_dbu,\n",
    "  pct_serverless_runs,\n",
    "  pct_serverless_dbu,\n",
    "  '' AS cluster_id,\n",
    "  '' AS cluster_name,\n",
    "  '' AS worker_node_type,\n",
    "  '' AS is_multi_worker,\n",
    "  '' AS max_worker_count,\n",
    "  '' AS is_autoscaling,\n",
    "  '' AS rank,\n",
    "  0 AS count_routines,\n",
    "  0 AS sum_photon_run,\n",
    "  0 AS sum_photon_dbu,\n",
    "  0 AS sum_non_photon_run,\n",
    "  0 AS sum_non_photon_dbu,\n",
    "  0 AS pct_photon_runs,\n",
    "  0 AS pct_photon_dbu\n",
    "FROM PE_01\n",
    "UNION ALL \n",
    "SELECT\n",
    "  waf_id,\n",
    "  '' AS principle,\n",
    "  '' AS best_practice,\n",
    "  '' AS implemented,\n",
    "  0 AS actual_perc,\n",
    "  0 AS required_percentage,\n",
    "  0 AS total_controls,\n",
    "  0 AS row_num,\n",
    "  0 AS implemented_controls,\n",
    "  0 AS completion_percent,\n",
    "  0 AS total_percentage,\n",
    "  dataset_type,\n",
    "  '' AS billing_origin_product,\n",
    "  runs AS runs_total,\n",
    "  dbu_usage AS dbu_usage_total, \n",
    "  0 AS sum_serverless_run,\n",
    "  0 AS sum_serverless_dbu,\n",
    "  0 AS sum_non_serverless_run,\n",
    "  0 AS sum_non_serverless_dbu,\n",
    "  0 AS pct_serverless_runs,\n",
    "  0 AS pct_serverless_dbu,\n",
    "  cluster_id,\n",
    "  cluster_name,\n",
    "  worker_node_type,\n",
    "  is_multi_worker,\n",
    "  max_worker_count,\n",
    "  is_autoscaling,\n",
    "  CASE WHEN rank <= 10 THEN 'Top 10' ELSE 'Others' END AS rank,\n",
    "  0 AS count_routines,\n",
    "  0 AS sum_photon_run,\n",
    "  0 AS sum_photon_dbu,\n",
    "  0 AS sum_non_photon_run,\n",
    "  0 AS sum_non_photon_dbu,\n",
    "  0 AS pct_photon_runs,\n",
    "  0 AS pct_photon_dbu\n",
    "FROM PE_02\n",
    "UNION ALL\n",
    "SELECT\n",
    "  waf_id,\n",
    "  '' AS principle,\n",
    "  '' AS best_practice,\n",
    "  '' AS implemented,\n",
    "  0 AS actual_perc,\n",
    "  0 AS required_percentage,\n",
    "  0 AS total_controls,\n",
    "  0 AS row_num,\n",
    "  0 AS implemented_controls,\n",
    "  0 AS completion_percent,\n",
    "  0 AS total_percentage,\n",
    "  dataset_type,\n",
    "  '' AS billing_origin_product,\n",
    "  0 AS runs_total,\n",
    "  0 AS dbu_usage_total, \n",
    "  0 AS sum_serverless_run,\n",
    "  0 AS sum_serverless_dbu,\n",
    "  0 AS sum_non_serverless_run,\n",
    "  0 AS sum_non_serverless_dbu,\n",
    "  0 AS pct_serverless_runs,\n",
    "  0 AS pct_serverless_dbu,\n",
    "  '' AS cluster_id,\n",
    "  '' AS cluster_name,\n",
    "  '' AS worker_node_type,\n",
    "  '' AS is_multi_worker,\n",
    "  '' AS max_worker_count,\n",
    "  '' AS is_autoscaling,\n",
    "  '' AS rank,\n",
    "  count_routines,\n",
    "  0 AS sum_photon_run,\n",
    "  0 AS sum_photon_dbu,\n",
    "  0 AS sum_non_photon_run,\n",
    "  0 AS sum_non_photon_dbu,\n",
    "  0 AS pct_photon_runs,\n",
    "  0 AS pct_photon_dbu\n",
    "FROM PE_02_05\n",
    "UNION ALL\n",
    "SELECT\n",
    "  waf_id,\n",
    "  '' AS principle,\n",
    "  '' AS best_practice,\n",
    "  '' AS implemented,\n",
    "  0 AS actual_perc,\n",
    "  0 AS required_percentage,\n",
    "  0 AS total_controls,\n",
    "  0 AS row_num,\n",
    "  0 AS implemented_controls,\n",
    "  0 AS completion_percent,\n",
    "  0 AS total_percentage,\n",
    "  dataset_type,\n",
    "  billing_origin_product,\n",
    "  runs_total,\n",
    "  dbu_usage_total, \n",
    "  0 AS sum_serverless_run,\n",
    "  0 AS sum_serverless_dbu,\n",
    "  0 AS sum_non_serverless_run,\n",
    "  0 AS sum_non_serverless_dbu,\n",
    "  0 AS pct_serverless_runs,\n",
    "  0 AS pct_serverless_dbu,\n",
    "  '' AS cluster_id,\n",
    "  '' AS cluster_name,\n",
    "  '' AS worker_node_type,\n",
    "  '' AS is_multi_worker,\n",
    "  '' AS max_worker_count,\n",
    "  '' AS is_autoscaling,\n",
    "  '' AS rank,\n",
    "  0 AS count_routines,\n",
    "  sum_photon_run,\n",
    "  sum_photon_dbu,\n",
    "  sum_non_photon_run,\n",
    "  sum_non_photon_dbu,\n",
    "  pct_photon_runs,\n",
    "  pct_photon_dbu\n",
    "FROM PE_02_06"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_0c235d96-4bc7-4fb5-b118-17fd1dad0124",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "waf_controls_performance",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
