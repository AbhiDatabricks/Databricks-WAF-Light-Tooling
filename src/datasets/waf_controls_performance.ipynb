{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b57d5b4d-fcf6-461f-91ad-a07d2bb4f4f9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define widgets"
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.widgets.text(\"date_filter_min\", \"2025-10-01\", \"Start Date\")\n",
    "# dbutils.widgets.text(\"date_filter_max\", \"2025-10-31\", \"End Date\")\n",
    "dbutils.widgets.text(\"workspace_id\", \"1444828305810485\", \"workspace id\")\n",
    "dbutils.widgets.text(\"catalog_name\", \"renjiharold_demo\", \"Catalog Name\")\n",
    "dbutils.widgets.text(\"schema_name\", \"waf_db\", \"Schema Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6edaf89d-e998-4e3a-a1b3-308ecb190503",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Session"
    }
   },
   "outputs": [],
   "source": [
    "# Get catalog and schema name from widgets\n",
    "catalog_name = dbutils.widgets.get(\"catalog_name\")\n",
    "schema_name = dbutils.widgets.get(\"schema_name\")\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8aedc0aa-0c0a-4191-a1cf-0d47b99c8260",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Calculate metrics for Performance"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE waf_performance\n",
    "AS\n",
    "WITH PE_01 AS (\n",
    "SELECT \n",
    "    billing_origin_product\n",
    "  , SUM(runs) AS runs_total\n",
    "  , SUM(dbu_usage) AS dbu_usage_total\n",
    "  , 'PE_01' AS waf_id\n",
    "  , 'Detailed' AS dataset_type\n",
    "  , SUM(CASE WHEN is_serverless = true THEN runs ELSE 0 END) AS sum_serverless_run\n",
    "  , SUM(CASE WHEN is_serverless = true THEN dbu_usage ELSE 0 END) AS sum_serverless_dbu\n",
    "  , SUM(CASE WHEN is_serverless = false THEN runs ELSE 0 END) AS sum_non_serverless_run\n",
    "  , SUM(CASE WHEN is_serverless = false THEN dbu_usage ELSE 0 END) AS sum_non_serverless_dbu\n",
    "  , SUM(CASE WHEN is_serverless = true THEN runs ELSE 0 END)/SUM(runs) AS pct_serverless_runs\n",
    "  , SUM(CASE WHEN is_serverless = true THEN dbu_usage ELSE 0 END)/SUM(dbu_usage) AS pct_serverless_dbu\n",
    "FROM \n",
    "(SELECT \n",
    "   COUNT(*) AS runs\n",
    "  ,SUM(usage_quantity) AS dbu_usage, CASE WHEN billing_origin_product = 'ALL_PURPOSE' THEN 'INTERACTIVE' ELSE billing_origin_product END AS billing_origin_product\n",
    "  , CASE WHEN sku_name LIKE '%SERVERLESS%' OR product_features.is_serverless = true THEN true ELSE false END AS is_serverless\n",
    " FROM system.billing.usage \n",
    "--  WHERE usage_date BETWEEN :date_filter_min AND :date_filter_max\n",
    " WHERE usage_date >= date_add(current_date(), -90)\n",
    "--  AND array_contains(:workspace_id,workspace_id)\n",
    " AND workspace_id = :workspace_id\n",
    " AND usage_unit = 'DBU'\n",
    " AND billing_origin_product IN ('JOBS','MODEL_SERVING','LAKEFLOW_CONNECT','SQL','INTERACTIVE','DLT','ALL_PURPOSE')\n",
    " GROUP BY CASE WHEN billing_origin_product = 'ALL_PURPOSE' THEN 'INTERACTIVE' ELSE billing_origin_product END, CASE WHEN sku_name LIKE '%SERVERLESS%' OR product_features.is_serverless = true THEN true ELSE false END \n",
    ")CTE\n",
    "GROUP BY\n",
    "billing_origin_product \n",
    "),\n",
    "PE_01_01_perc AS (\n",
    "  SELECT \n",
    "    ROUND((SUM(sum_serverless_dbu)/SUM(dbu_usage_total))*100,2) AS actual_perc,\n",
    "    'PE-01-01' AS waf_id,\n",
    "    'Percentage' AS dataset_type\n",
    "  FROM PE_01\n",
    "  WHERE billing_origin_product <> 'MODEL_SERVING'\n",
    "),\n",
    "-- WAF_PE-02-*_cluster_metrics\n",
    "usage AS (    \n",
    "  SELECT usage_metadata.cluster_id AS cluster_id, account_id, workspace_id\n",
    "  , count(*) as runs, SUM(usage_quantity) AS dbu_usage FROM system.billing.usage \n",
    "    -- WHERE usage_date BETWEEN :date_filter_min AND :date_filter_max\n",
    "     WHERE usage_date >= date_add(current_date(), -90)\n",
    "    --  AND array_contains(:workspace_id,workspace_id)\n",
    "    AND workspace_id = :workspace_id\n",
    "    AND usage_metadata.cluster_id IS NOT NULL\n",
    "    GROUP BY account_id, workspace_id, usage_metadata.cluster_id\n",
    "),\n",
    "compute_met AS (\n",
    "  SELECT * FROM \n",
    "    (select  row_number() over(partition by account_id, workspace_id, cluster_id order by change_time desc) AS rn\n",
    "        , account_id, workspace_id, c.cluster_id, c.cluster_name, c.worker_node_type, worker_count, max_autoscale_workers, min_autoscale_workers\n",
    "    from system.compute.clusters c \n",
    "    -- WHERE array_contains(:workspace_id,workspace_id)\n",
    "    WHERE workspace_id = :workspace_id\n",
    "    AND change_date <= date_add(current_date(), -90)) --TBD to check this filter\n",
    "    WHERE rn = 1\n",
    "),\n",
    "PE_02 AS (\n",
    "  SELECT \n",
    "       *\n",
    "      , row_number() over( order by dbu_usage desc) AS rank\n",
    "      , 'PE_02' AS waf_id\n",
    "      , 'Detailed' AS dataset_type\n",
    "    FROM(\n",
    "      SELECT SUM(u.dbu_usage) AS dbu_usage, SUM(u.runs) AS runs, c.cluster_id, c.cluster_name, c.worker_node_type\n",
    "            ,CASE WHEN ifnull(worker_count,ifnull(max_autoscale_workers,0)) > 1 THEN 'Multi-Node' ELSE 'Single-Node' END AS is_multi_worker\n",
    "            , ifnull(worker_count,ifnull(max_autoscale_workers,0)) AS max_worker_count\n",
    "            , CASE WHEN ifnull(c.min_autoscale_workers,0) = ifnull(c.max_autoscale_workers,0) THEN 0 ELSE 1 END AS is_autoscaling\n",
    "      FROM\n",
    "      usage u\n",
    "      INNER JOIN\n",
    "      compute_met c\n",
    "      ON u.cluster_id = c.cluster_id\n",
    "      AND u.account_id = c.account_id\n",
    "      AND u.workspace_id = c.workspace_id\n",
    "      GROUP BY\n",
    "      c.cluster_id, c.cluster_name, c.worker_node_type\n",
    "      ,CASE WHEN ifnull(worker_count,ifnull(max_autoscale_workers,0)) > 1 THEN 'Multi-Node' ELSE 'Single-Node' END\n",
    "      , ifnull(worker_count,ifnull(max_autoscale_workers,0)) \n",
    "      , CASE WHEN ifnull(c.min_autoscale_workers,0) = ifnull(c.max_autoscale_workers,0) THEN 0 ELSE 1 END \n",
    "    )\n",
    "),\n",
    "PE_02_02_perc AS (\n",
    "  SELECT \n",
    "    ROUND((SUM(CASE WHEN is_multi_worker = 'Multi-Node' THEN 1 ELSE 0 END)/COUNT(*))*100,2) AS actual_perc,\n",
    "    'PE-02-02' AS waf_id\n",
    "    , 'Percentage' AS dataset_type\n",
    "  FROM PE_02\n",
    "),\n",
    "PE_02_04_perc AS (\n",
    "  SELECT \n",
    "    ROUND((SUM(CASE WHEN max_worker_count > 3 THEN 1 ELSE 0 END)/COUNT(*))*100,2) AS actual_perc,\n",
    "    'PE-02-04' AS waf_id\n",
    "    , 'Percentage' AS dataset_type\n",
    "  FROM PE_02\n",
    "),\n",
    "PE_02_05 AS (\n",
    "  SELECT \n",
    "    'PE_02_05' AS waf_id,\n",
    "    'Detailed' AS dataset_type,\n",
    "    COUNT(*) as count_routines\n",
    "  FROM system.information_schema.routines WHERE external_language = 'Python' \n",
    "),\n",
    "\n",
    "PE_02_06 AS (\n",
    "  SELECT \n",
    "    'PE_02_06' AS waf_id\n",
    "  , 'Detailed' AS dataset_type\n",
    "  , billing_origin_product\n",
    "  , SUM(runs) AS runs_total\n",
    "  , SUM(dbu_usage) AS dbu_usage_total\n",
    "  , SUM(CASE WHEN is_photon = true THEN runs ELSE 0 END) AS sum_photon_run\n",
    "  , SUM(CASE WHEN is_photon = true THEN dbu_usage ELSE 0 END) AS sum_photon_dbu\n",
    "  , SUM(CASE WHEN is_photon = false THEN runs ELSE 0 END) AS sum_non_photon_run\n",
    "  , SUM(CASE WHEN is_photon = false THEN dbu_usage ELSE 0 END) AS sum_non_photon_dbu\n",
    "  , SUM(CASE WHEN is_photon = true THEN runs ELSE 0 END)/SUM(runs) AS pct_photon_runs\n",
    "  , SUM(CASE WHEN is_photon = true THEN dbu_usage ELSE 0 END)/SUM(dbu_usage) AS pct_photon_dbu\n",
    "  FROM (\n",
    "    SELECT COUNT(*) AS runs,SUM(usage_quantity) AS dbu_usage, billing_origin_product\n",
    "    , CASE WHEN sku_name LIKE '%PHOTON%' OR product_features.is_photon = true THEN true ELSE false END AS is_photon\n",
    "    FROM system.billing.usage \n",
    "    -- WHERE usage_date BETWEEN :date_filter_min AND :date_filter_max\n",
    "    WHERE usage_date >= date_add(current_date(), -90)\n",
    "    -- AND array_contains(:workspace_id,workspace_id)\n",
    "    AND workspace_id = :workspace_id\n",
    "    AND billing_origin_product  IN ('JOBS','LAKEFLOW_CONNECT','VECTOR_SEARCH','DATABASE','DLT','ALL_PURPOSE','ONLINE_TABLES','INTERACTIVE')\n",
    "    AND usage_unit = 'DBU'\n",
    "    GROUP BY billing_origin_product, CASE WHEN sku_name LIKE '%PHOTON%' OR product_features.is_photon = true THEN true ELSE false END \n",
    ")\n",
    "GROUP BY\n",
    "billing_origin_product \n",
    "),\n",
    "PE_02_06_perc AS \n",
    "(\n",
    "  SELECT \n",
    "    ROUND((SUM(sum_photon_dbu)/SUM(dbu_usage_total))*100,2) AS actual_perc,\n",
    "    'PE-02-06' AS waf_id,\n",
    "    'Percentage' AS dataset_type\n",
    "  FROM PE_02_06\n",
    "),\n",
    "PE_02_07_perc AS \n",
    "(\n",
    "  SELECT \n",
    "    ROUND((COUNT(DISTINCT split(worker_node_type,'[.]')[0])/COUNT(1))*100,2) AS actual_perc,\n",
    "    'PE-02-07' AS waf_id,\n",
    "    'Percentage' AS dataset_type\n",
    "  FROM PE_02\n",
    "),\n",
    "\n",
    "\n",
    "waf_status AS(\n",
    "SELECT\n",
    "  waf.waf_id,\n",
    "  principle,\n",
    "  best_practice,\n",
    "  COALESCE(p11p.actual_perc,p22p.actual_perc,p24p.actual_perc,p26p.actual_perc,p27p.actual_perc,0.00) AS actual_perc,\n",
    "  CASE \n",
    "    WHEN waf.waf_id = 'PE-01-02' AND EXISTS (\n",
    "      SELECT 1 FROM PE_01 WHERE billing_origin_product = 'MODEL_SERVING' LIMIT 1\n",
    "    ) THEN 'Yes' --TBD dbu usage limit?\n",
    "    WHEN waf.waf_id = 'PE-02-05' AND NOT EXISTS (\n",
    "      SELECT 1 FROM PE_02_05 LIMIT 1 \n",
    "    ) THEN 'Yes'\n",
    "    WHEN waf.waf_id NOT IN ('PE-01-02','PE-02-05') \n",
    "          AND  required_percentage <= COALESCE(p11p.actual_perc,p22p.actual_perc,p24p.actual_perc,p26p.actual_perc,p27p.actual_perc,0) THEN 'Yes'\n",
    "    ELSE 'No'\n",
    "  END AS implemented,\n",
    "  required_percentage\n",
    "FROM (\n",
    "  SELECT * FROM VALUES\n",
    "    ('PE-01-01', 'Utilize serverless capabilities', 'Use serverless architecture',30),\n",
    "    ('PE-01-02', 'Utilize serverless capabilities', 'Use an enterprise grade model serving service',0),\n",
    "    --('PE-02-01', 'Utilize serverless capabilities', 'Understand your data ingestion and access patterns'),\n",
    "    ('PE-02-02', 'Design workloads for performance', 'Use parallel computation where it is beneficial',30),\n",
    "    --('PE-02-03', 'Design workloads for performance', 'Analyze the whole chain of execution'),\n",
    "    ('PE-02-04', 'Design workloads for performance', 'Prefer larger clusters',30),\n",
    "    ('PE-02-05', 'Design workloads for performance', 'Use native Spark operations',0),\n",
    "    ('PE-02-06', 'Design workloads for performance', 'Use native platform engines',30),\n",
    "    ('PE-02-07', 'Design workloads for performance', 'Understand your hardware and workload type',20)\n",
    "    --('PE-02-08', 'Design workloads for performance', 'Use caching'),\n",
    "    --('PE-02-09', 'Design workloads for performance', 'Use compaction'),\n",
    ") waf(waf_id, principle, best_practice,required_percentage)\n",
    "LEFT JOIN \n",
    "PE_01_01_perc p11p\n",
    "ON waf.waf_id = p11p.waf_id\n",
    "LEFT JOIN \n",
    "PE_02_02_perc p22p\n",
    "ON waf.waf_id = p22p.waf_id\n",
    "LEFT JOIN\n",
    "PE_02_04_perc p24p\n",
    "ON waf.waf_id = p24p.waf_id\n",
    "LEFT JOIN\n",
    "PE_02_06_perc p26p\n",
    "ON waf.waf_id = p26p.waf_id\n",
    "LEFT JOIN\n",
    "PE_02_07_perc p27p\n",
    "ON waf.waf_id = p27p.waf_id\n",
    ")\n",
    "SELECT\n",
    "  waf_id,\n",
    "  principle,\n",
    "  best_practice,\n",
    "  implemented,\n",
    "  actual_perc,\n",
    "  required_percentage,\n",
    "  COUNT(*) OVER (PARTITION BY principle) AS total_controls,\n",
    "  ROW_NUMBER() OVER (PARTITION BY principle ORDER BY waf_id) AS row_num,\n",
    "  SUM(CASE WHEN implemented = 'Yes' THEN 1 ELSE 0 END) OVER (PARTITION BY principle) AS implemented_controls,\n",
    "  ROUND(100 * SUM(CASE WHEN implemented = 'Yes' THEN 1 ELSE 0 END) OVER (PARTITION BY principle)/ COUNT(*) OVER (PARTITION BY principle) , 0) AS completion_percent,\n",
    "  ROUND(100 * SUM(CASE WHEN implemented = 'Yes' THEN 1 ELSE 0 END) OVER () / COUNT(*) OVER (), 0) AS total_percentage,\n",
    "  'Summary' AS dataset_type,\n",
    "  '' AS billing_origin_product,\n",
    "  0 AS runs_total,\n",
    "  0 AS dbu_usage_total, \n",
    "  0 AS sum_serverless_run,\n",
    "  0 AS sum_serverless_dbu,\n",
    "  0 AS sum_non_serverless_run,\n",
    "  0 AS sum_non_serverless_dbu,\n",
    "  0 AS pct_serverless_runs,\n",
    "  0 AS pct_serverless_dbu,\n",
    "  '' AS cluster_id,\n",
    "  '' AS cluster_name,\n",
    "  '' AS worker_node_type,\n",
    "  '' AS is_multi_worker,\n",
    "  0 AS max_worker_count,\n",
    "  NULL AS is_autoscaling,\n",
    "  '' AS rank,\n",
    "  0 AS count_routines,\n",
    "  0 AS sum_photon_run,\n",
    "  0 AS sum_photon_dbu,\n",
    "  0 AS sum_non_photon_run,\n",
    "  0 AS sum_non_photon_dbu,\n",
    "  0 AS pct_photon_runs,\n",
    "  0 AS pct_photon_dbu\n",
    "FROM waf_status\n",
    "UNION ALL\n",
    "SELECT\n",
    "  waf_id,\n",
    "  '' AS principle,\n",
    "  '' AS best_practice,\n",
    "  '' AS implemented,\n",
    "  0 AS actual_perc,\n",
    "  0 AS required_percentage,\n",
    "  0 AS total_controls,\n",
    "  0 AS row_num,\n",
    "  0 AS implemented_controls,\n",
    "  0 AS completion_percent,\n",
    "  0 AS total_percentage,\n",
    "  dataset_type,\n",
    "  billing_origin_product,\n",
    "  runs_total,\n",
    "  dbu_usage_total, \n",
    "  sum_serverless_run,\n",
    "  sum_serverless_dbu,\n",
    "  sum_non_serverless_run,\n",
    "  sum_non_serverless_dbu,\n",
    "  pct_serverless_runs,\n",
    "  pct_serverless_dbu,\n",
    "  '' AS cluster_id,\n",
    "  '' AS cluster_name,\n",
    "  '' AS worker_node_type,\n",
    "  '' AS is_multi_worker,\n",
    "  0 AS max_worker_count,\n",
    "  NULL AS is_autoscaling,\n",
    "  '' AS rank,\n",
    "  0 AS count_routines,\n",
    "  0 AS sum_photon_run,\n",
    "  0 AS sum_photon_dbu,\n",
    "  0 AS sum_non_photon_run,\n",
    "  0 AS sum_non_photon_dbu,\n",
    "  0 AS pct_photon_runs,\n",
    "  0 AS pct_photon_dbu\n",
    "FROM PE_01\n",
    "UNION ALL \n",
    "SELECT\n",
    "  waf_id,\n",
    "  '' AS principle,\n",
    "  '' AS best_practice,\n",
    "  '' AS implemented,\n",
    "  0 AS actual_perc,\n",
    "  0 AS required_percentage,\n",
    "  0 AS total_controls,\n",
    "  0 AS row_num,\n",
    "  0 AS implemented_controls,\n",
    "  0 AS completion_percent,\n",
    "  0 AS total_percentage,\n",
    "  dataset_type,\n",
    "  '' AS billing_origin_product,\n",
    "  runs AS runs_total,\n",
    "  dbu_usage AS dbu_usage_total, \n",
    "  0 AS sum_serverless_run,\n",
    "  0 AS sum_serverless_dbu,\n",
    "  0 AS sum_non_serverless_run,\n",
    "  0 AS sum_non_serverless_dbu,\n",
    "  0 AS pct_serverless_runs,\n",
    "  0 AS pct_serverless_dbu,\n",
    "  cluster_id,\n",
    "  cluster_name,\n",
    "  worker_node_type,\n",
    "  is_multi_worker,\n",
    "  max_worker_count,\n",
    "  is_autoscaling,\n",
    "  CASE WHEN rank <= 10 THEN 'Top 10' ELSE 'Others' END AS rank,\n",
    "  0 AS count_routines,\n",
    "  0 AS sum_photon_run,\n",
    "  0 AS sum_photon_dbu,\n",
    "  0 AS sum_non_photon_run,\n",
    "  0 AS sum_non_photon_dbu,\n",
    "  0 AS pct_photon_runs,\n",
    "  0 AS pct_photon_dbu\n",
    "FROM PE_02\n",
    "UNION ALL\n",
    "SELECT\n",
    "  waf_id,\n",
    "  '' AS principle,\n",
    "  '' AS best_practice,\n",
    "  '' AS implemented,\n",
    "  0 AS actual_perc,\n",
    "  0 AS required_percentage,\n",
    "  0 AS total_controls,\n",
    "  0 AS row_num,\n",
    "  0 AS implemented_controls,\n",
    "  0 AS completion_percent,\n",
    "  0 AS total_percentage,\n",
    "  dataset_type,\n",
    "  '' AS billing_origin_product,\n",
    "  0 AS runs_total,\n",
    "  0 AS dbu_usage_total, \n",
    "  0 AS sum_serverless_run,\n",
    "  0 AS sum_serverless_dbu,\n",
    "  0 AS sum_non_serverless_run,\n",
    "  0 AS sum_non_serverless_dbu,\n",
    "  0 AS pct_serverless_runs,\n",
    "  0 AS pct_serverless_dbu,\n",
    "  '' AS cluster_id,\n",
    "  '' AS cluster_name,\n",
    "  '' AS worker_node_type,\n",
    "  '' AS is_multi_worker,\n",
    "  0 AS max_worker_count,\n",
    "  NULL AS is_autoscaling,\n",
    "  '' AS rank,\n",
    "  count_routines,\n",
    "  0 AS sum_photon_run,\n",
    "  0 AS sum_photon_dbu,\n",
    "  0 AS sum_non_photon_run,\n",
    "  0 AS sum_non_photon_dbu,\n",
    "  0 AS pct_photon_runs,\n",
    "  0 AS pct_photon_dbu\n",
    "FROM PE_02_05\n",
    "UNION ALL\n",
    "SELECT\n",
    "  waf_id,\n",
    "  '' AS principle,\n",
    "  '' AS best_practice,\n",
    "  '' AS implemented,\n",
    "  0 AS actual_perc,\n",
    "  0 AS required_percentage,\n",
    "  0 AS total_controls,\n",
    "  0 AS row_num,\n",
    "  0 AS implemented_controls,\n",
    "  0 AS completion_percent,\n",
    "  0 AS total_percentage,\n",
    "  dataset_type,\n",
    "  billing_origin_product,\n",
    "  runs_total,\n",
    "  dbu_usage_total, \n",
    "  0 AS sum_serverless_run,\n",
    "  0 AS sum_serverless_dbu,\n",
    "  0 AS sum_non_serverless_run,\n",
    "  0 AS sum_non_serverless_dbu,\n",
    "  0 AS pct_serverless_runs,\n",
    "  0 AS pct_serverless_dbu,\n",
    "  '' AS cluster_id,\n",
    "  '' AS cluster_name,\n",
    "  '' AS worker_node_type,\n",
    "  '' AS is_multi_worker,\n",
    "  0 AS max_worker_count,\n",
    "  NULL AS is_autoscaling,\n",
    "  '' AS rank,\n",
    "  0 AS count_routines,\n",
    "  sum_photon_run,\n",
    "  sum_photon_dbu,\n",
    "  sum_non_photon_run,\n",
    "  sum_non_photon_dbu,\n",
    "  pct_photon_runs,\n",
    "  pct_photon_dbu\n",
    "FROM PE_02_06\n",
    "ORDER BY waf_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "dd1d9ba8-ffa4-46fa-8d0e-47d603574f91",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Log Run"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "INSERT INTO waf_log (run_date, current_percent, prev_percent, percent_change, pillar)\n",
    "SELECT\n",
    "  current_timestamp(),\n",
    "  total_percentage,\n",
    "  prev_percent,\n",
    "  CASE\n",
    "    WHEN prev_percent IS NULL OR prev_percent = 0 THEN 0\n",
    "    ELSE ROUND((total_percentage - prev_percent) / prev_percent * 100, 2)\n",
    "  END AS percent_change,\n",
    "  'performance'\n",
    "FROM (\n",
    "  SELECT\n",
    "    total_percentage,\n",
    "    (SELECT \n",
    "      current_percent\n",
    "     FROM waf_log\n",
    "     WHERE pillar = 'performance'\n",
    "     ORDER BY run_id DESC\n",
    "     LIMIT 1) AS prev_percent\n",
    "  FROM waf_performance\n",
    "  WHERE dataset_type = 'Summary'\n",
    "  LIMIT 1\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_0c235d96-4bc7-4fb5-b118-17fd1dad0124",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5573629765068713,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2,
    "widgetLayout": [
     {
      "breakBefore": false,
      "name": "date_filter_min",
      "width": 216
     },
     {
      "breakBefore": false,
      "name": "date_filter_max",
      "width": 216
     },
     {
      "breakBefore": false,
      "name": "workspace_id",
      "width": 216
     }
    ]
   },
   "notebookName": "waf_controls_performance",
   "widgets": {
    "catalog_name": {
     "currentValue": "renjiharold_demo",
     "nuid": "3788ee09-6b9a-41a9-bcc7-f80319052387",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "renjiharold_demo",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "renjiharold_demo",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "schema_name": {
     "currentValue": "waf_db",
     "nuid": "ba85623a-ed91-4d41-8c2b-be22f571124e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "waf_db",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "waf_db",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "workspace_id": {
     "currentValue": "1444828305810485",
     "nuid": "d2af23ec-650a-4761-b812-bd5a75432429",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "1444828305810485",
      "label": "workspace id",
      "name": "workspace_id",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "1444828305810485",
      "label": "workspace id",
      "name": "workspace_id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
