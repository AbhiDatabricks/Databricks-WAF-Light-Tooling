WITH delta_usage AS (
  SELECT 
    COUNT(*) as total_tables,
    SUM(CASE WHEN data_source_format IN ('DELTA', 'ICEBERG') THEN 1 ELSE 0 END) as delta_tables
  FROM system.information_schema.tables
  WHERE table_catalog != 'hive_metastore'
),
dlt_usage AS (
  SELECT 
    COUNT(*) as total_compute_usage,
    SUM(CASE WHEN billing_origin_product = 'DLT' THEN 1 ELSE 0 END) as dlt_compute_usage
  FROM system.billing.usage
  WHERE usage_start_time >= CURRENT_DATE - INTERVAL '30' DAY
    AND usage_type LIKE '%COMPUTE%'
),
model_serving_usage AS (
  SELECT 
    COUNT(*) as total_ml_compute,
    SUM(CASE WHEN billing_origin_product = 'MODEL_SERVING' THEN 1 ELSE 0 END) as serving_compute
  FROM system.billing.usage
  WHERE usage_start_time >= CURRENT_DATE - INTERVAL '30' DAY
    AND (usage_type LIKE '%COMPUTE%' OR billing_origin_product = 'MODEL_SERVING')
),
serverless_usage AS (
  SELECT 
    COUNT(*) as total_compute,
    SUM(CASE WHEN usage_type LIKE '%SERVERLESS%' OR sku_name LIKE '%SERVERLESS%' THEN 1 ELSE 0 END) as serverless_count
  FROM system.billing.usage
  WHERE usage_start_time >= CURRENT_DATE - INTERVAL '30' DAY
    AND usage_type LIKE '%COMPUTE%'
),
autoscale_clusters AS (
  SELECT 
    COUNT(*) as total_clusters,
    SUM(CASE WHEN ifnull(max_autoscale_Workers, 0) > 0 THEN 1 ELSE 0 END) as autoscale_clusters
  FROM system.compute.clusters
),
autoscale_warehouses AS (
  SELECT 
    COUNT(*) as total_warehouses,
    SUM(CASE WHEN max_clusters - min_clusters > 0 THEN 1 ELSE 0 END) as autoscale_warehouses
  FROM system.compute.warehouses
),
waf_status AS (
  SELECT
    waf_id,
    CASE 
    -- R-01-01: >80% of tables use Delta/ICEBERG format
    WHEN waf_id = 'R-01-01' AND (
      SELECT CASE WHEN total_tables > 0 THEN (delta_tables * 100.0 / total_tables) ELSE 0 END
      FROM delta_usage
    ) >= 80 THEN 'Yes'
    -- R-01-03: >30% of compute usage is DLT
    WHEN waf_id = 'R-01-03' AND (
      SELECT CASE WHEN total_compute_usage > 0 THEN (dlt_compute_usage * 100.0 / total_compute_usage) ELSE 0 END
      FROM dlt_usage
    ) >= 30 THEN 'Yes'
    -- R-01-05: Model Serving actively used (>20% of ML compute usage)
    WHEN waf_id = 'R-01-05' AND (
      SELECT CASE WHEN total_ml_compute > 0 THEN (serving_compute * 100.0 / total_ml_compute) ELSE 0 END
      FROM model_serving_usage
    ) >= 20 THEN 'Yes'
    -- R-01-06: >50% of compute is serverless or managed
    WHEN waf_id = 'R-01-06' AND (
      SELECT CASE WHEN total_compute > 0 THEN (serverless_count * 100.0 / total_compute) ELSE 0 END
      FROM serverless_usage
    ) >= 50 THEN 'Yes'
    -- R-02-03: Unity Catalog metastore exists
    WHEN waf_id = 'R-02-03' AND EXISTS (
      SELECT 1 FROM system.information_schema.metastores LIMIT 1
    ) THEN 'Yes'
    -- R-02-04: >30% of compute usage is DLT (same as R-01-03)
    WHEN waf_id = 'R-02-04' AND (
      SELECT CASE WHEN total_compute_usage > 0 THEN (dlt_compute_usage * 100.0 / total_compute_usage) ELSE 0 END
      FROM dlt_usage
    ) >= 30 THEN 'Yes'
    -- R-03-01: >80% of clusters have auto-scaling enabled
    WHEN waf_id = 'R-03-01' AND (
      SELECT CASE WHEN total_clusters > 0 THEN (autoscale_clusters * 100.0 / total_clusters) ELSE 0 END
      FROM autoscale_clusters
    ) >= 80 THEN 'Yes'
    -- R-03-02: >80% of warehouses have auto-scaling enabled
    WHEN waf_id = 'R-03-02' AND (
      SELECT CASE WHEN total_warehouses > 0 THEN (autoscale_warehouses * 100.0 / total_warehouses) ELSE 0 END
      FROM autoscale_warehouses
    ) >= 80 THEN 'Yes'
    ELSE 'No'
  END AS implemented
  FROM (
    SELECT * FROM VALUES
    ('R-01-01'),
    --('R-01-02'), -- Removed: Apache Spark always available in Databricks
    ('R-01-03'),
    --('R-01-04'),
    ('R-01-05'),
    ('R-01-06'),
    ('R-02-03'),
    ('R-02-04'),
    ('R-03-01'),
    ('R-03-02')
    AS waf(waf_id)
  )
)

SELECT
  COUNT(*) AS total_controls,
  SUM(CASE WHEN implemented = 'Yes' THEN 1 ELSE 0 END) AS implemented_controls,
  ROUND(100 * SUM(CASE WHEN implemented = 'Yes' THEN 1 ELSE 0 END) / COUNT(*), 0) AS completion_percent
FROM waf_status;
